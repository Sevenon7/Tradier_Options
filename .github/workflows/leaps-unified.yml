name: LEAPS Unified (produce + consume)

on:
  # 10:50 AM local PT (DST-aware, weekdays only)
  # PDT (Mar–Oct) 17:50 UTC
  schedule:
    - cron: '50 17 * 3-10 1-5'
    # PST (Nov–Feb) 18:50 UTC
    - cron: '50 18 * 11,12,1,2 1-5'
  workflow_dispatch:

permissions:
  contents: write   # commit output + publish gh-pages
  pages: write

env:
  PYTHON_VERSION: "3.11"
  DESIRED_PT_TIME: "10:50"   # target local PT fire time
  WINDOW_MIN: "35"           # ± minutes allowed around target (keeps single daily run)
  REPO: "Sevenon7/Tradier_Options"
  BRANCH: "main"
  OWNER: "Sevenon7"

jobs:
  # =========================
  # 1) TIME GATE (PT window)
  # =========================
  time-gate:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      run_ok: ${{ steps.tgate.outputs.run_ok }}
    steps:
      - name: Time Gate (America/Los_Angeles)
        id: tgate
        shell: bash
        run: |
          set -euo pipefail
          export TZ=America/Los_Angeles
          NOW_PT="$(date +%H:%M)"
          TARGET_PT="${DESIRED_PT_TIME}"

          # Compute |Δ| minutes between NOW_PT and TARGET_PT using GNU date
          now_s="$(date -d "$NOW_PT" +%s)"
          tgt_s="$(date -d "$TARGET_PT" +%s)"
          diff="$(( now_s - tgt_s ))"; [ "$diff" -lt 0 ] && diff="$(( -diff ))"
          DELTA="$(( diff / 60 ))"

          echo "Now PT: ${NOW_PT}" >> "$GITHUB_STEP_SUMMARY"
          echo "Target PT: ${TARGET_PT}" >> "$GITHUB_STEP_SUMMARY"
          echo "Delta (min): ${DELTA}" >> "$GITHUB_STEP_SUMMARY"
          echo "Window (±min): ${WINDOW_MIN}" >> "$GITHUB_STEP_SUMMARY"

          if [ "${DELTA}" -le "${WINDOW_MIN}" ]; then
            echo "run_ok=true"  >> "$GITHUB_OUTPUT"
            echo "✅ Within window — proceeding." >> "$GITHUB_STEP_SUMMARY"
          else
            echo "run_ok=false" >> "$GITHUB_OUTPUT"
            echo "⏸️ Outside window — skipping execution." >> "$GITHUB_STEP_SUMMARY"
          fi

  # =========================
  # 2) PRODUCER
  # =========================
  producer:
    needs: time-gate
    if: needs.time-gate.outputs.run_ok == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 25
    outputs:
      date_dir: ${{ steps.collect.outputs.date_dir }}
      already_ran: ${{ steps.skipcheck.outputs.already }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Ensure OS tools (curl/jq)
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y curl jq coreutils

      - name: Create requirements.txt (deterministic)
        run: |
          set -euo pipefail
          printf '%s\n' \
            'requests' \
            'pandas' \
            'numpy' \
            'python-dateutil' > requirements.txt
          echo "----- requirements.txt -----"
          cat requirements.txt

      - name: Install deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Mask token (log hygiene)
        run: echo "::add-mask::${{ secrets.TRADIER_TOKEN }}"

      - name: Skip if already ran today (UTC)
        id: skipcheck
        shell: bash
        run: |
          set -euo pipefail
          DATE_DIR="data/$(date -u +%Y-%m-%d)"
          if [ -d "$DATE_DIR" ]; then
            echo "already=true"  >> "$GITHUB_OUTPUT"
            echo "⏭️ Producer already completed for $DATE_DIR" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "already=false" >> "$GITHUB_OUTPUT"
            echo "✨ First run for $DATE_DIR — executing Producer." >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Run overlay script (leaps_batched_cached.py)
        if: steps.skipcheck.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -euo pipefail
          python leaps_batched_cached.py

      - name: Build Actual Option P/L (tools/option_pl_builder.py)
        if: steps.skipcheck.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          if [ -f tools/option_pl_builder.py ]; then
            python tools/option_pl_builder.py
          else
            echo "⚠️ tools/option_pl_builder.py not present; skipping." >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Enrich overlay with intraday VWAP (optional)
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          if [ -f tools/enrich_overlay_with_vwap.py ]; then
            if ! python tools/enrich_overlay_with_vwap.py --overlay overlay_vwap_macd_rsi.csv; then
              echo "⚠️ VWAP enrichment failed (non-critical)" >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            echo "⚠️ tools/enrich_overlay_with_vwap.py not found; skipping." >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Collect artifacts into date dir + update latest.json
        if: steps.skipcheck.outputs.already == 'false'
        id: collect
        shell: bash
        run: |
          set -euo pipefail
          TODAY="$(date -u +%Y-%m-%d)"
          DD="data/${TODAY}"
          mkdir -p "$DD"

          # Move any root-level outputs into the date folder
          for f in overlay_vwap_macd_rsi.csv option_pl.csv gapdown_above_100sma.csv vwap_missing.json; do
            [ -f "$f" ] && mv -f "$f" "$DD/"
          done

          # Refresh latest.json pointer at repo root
          echo '{"date_dir":"data/'"${TODAY}"'"}' > latest.json

          echo "date_dir=${TODAY}" >> "$GITHUB_OUTPUT"

          {
            echo "### 📦 Producer Artifacts"
            echo "- **Directory:** \`${DD}\`"
            echo "- **Contents:**"
            ls -lh "$DD" | tail -n +2 | awk '{printf "  - `%s` (%s)\n", $9, $5}'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Commit daily artifacts to repo
        if: steps.skipcheck.outputs.already == 'false'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "LEAPS daily overlay (producer)"
          branch: ${{ env.BRANCH }}
          add_options: -A

      - name: Publish CSV mirror to gh-pages (static backup)
        if: steps.skipcheck.outputs.already == 'false'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: data/${{ steps.collect.outputs.date_dir }}
          destination_dir: data/${{ steps.collect.outputs.date_dir }}
          keep_files: true

  # =========================
  # 3) CONSUMER
  # =========================
  consumer:
    needs: [time-gate, producer]
    if: needs.time-gate.outputs.run_ok == 'true' && !cancelled()
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Ensure OS tools
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y curl jq coreutils

      - name: Make fetch tool executable (repo path)
        run: chmod +x tools/fetch.sh

      - name: Resolve effective date_dir (prefer latest.json; else newest ≤24h; else yesterday)
        id: datedir
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ env.REPO }}
          BRANCH: ${{ env.BRANCH }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p tmp
          TODAY="$(date -u +%Y-%m-%d)"
          # Try latest.json (non-critical)
          tools/fetch.sh latest.json tmp/latest.json || true

          # List /data folders via API
          curl -fsSL -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${GITHUB_TOKEN}" \
            "https://api.github.com/repos/${REPO}/contents/data?ref=${BRANCH}" > tmp/list.json

          python - <<'PY' > tmp/dd.txt
          import os, json, re, datetime, sys
          
          today = os.environ.get("TODAY")
          if not today:
              today = datetime.datetime.utcnow().strftime("%Y-%m-%d")
          
          # Load available date dirs
          with open("tmp/list.json","r",encoding="utf-8") as f:
              arr = json.load(f)
          dates = sorted([x["name"] for x in arr if x.get("type")=="dir" and re.fullmatch(r"\d{4}-\d{2}-\d{2}", x.get("name",""))])
          if not dates:
              print("ERROR: no date folders in /data", file=sys.stderr)
              sys.exit(1)
          
          today_dt = datetime.datetime.strptime(today, "%Y-%m-%d")
          cand = [d for d in dates if datetime.datetime.strptime(d,"%Y-%m-%d") <= today_dt]
          chosen = cand[-1] if cand else dates[-1]
          
          # If latest.json exists and is fresh (<=24h), prefer it
          try:
              with open("tmp/latest.json","r",encoding="utf-8") as f:
                  j = json.load(f)
              ptr = (j.get("date_dir") or "").split("/")[-1]
              if re.fullmatch(r"\d{4}-\d{2}-\d{2}", ptr) and ptr in dates:
                  ptr_dt = datetime.datetime.strptime(ptr, "%Y-%m-%d")
                  age_h = (today_dt - ptr_dt).total_seconds()/3600.0
                  if 0 <= age_h <= 24:
                      chosen = ptr
          except Exception:
              pass
          
          # If chosen is >24h, fall back to yesterday
          chosen_dt = datetime.datetime.strptime(chosen, "%Y-%m-%d")
          age_h = (today_dt - chosen_dt).total_seconds()/3600.0
          if age_h > 24:
              chosen = (today_dt - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
          
          print(chosen)
          PY

          if [ ! -s tmp/dd.txt ]; then
            echo "::error ::Failed to resolve date_dir"
            exit 1
          fi
          echo "date_dir=$(cat tmp/dd.txt)" >> "$GITHUB_OUTPUT"
          echo "Resolved date_dir: $(cat tmp/dd.txt)" >> "$GITHUB_STEP_SUMMARY"

      - name: Fetch overlay/PL/gap with fallback chain (raw → API → Pages)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ env.REPO }}
          BRANCH: ${{ env.BRANCH }}
        shell: bash
        run: |
          set -euo pipefail
          DD="${{ steps.datedir.outputs.date_dir }}"
          tools/fetch.sh \
            "data/${DD}/overlay_vwap_macd_rsi.csv" overlay.csv \
            "data/${DD}/option_pl.csv"            option_pl.csv \
            "data/${DD}/gapdown_above_100sma.csv" gap.csv

      - name: Emit quick summary to Job Summary
        run: |
          {
            echo "### 📊 Consumer Summary"
            echo "- **date_dir:** ${{ steps.datedir.outputs.date_dir }}"
            echo ""
            if [ -f overlay.csv ]; then
              echo "**overlay.csv (head):**"
              head -5 overlay.csv
              echo ""
            else
              echo "⚠️ overlay.csv not found"
            fi
            if [ -f option_pl.csv ]; then
              echo "**option_pl.csv (head):**"
              head -5 option_pl.csv
              echo ""
            else
              echo "⚠️ option_pl.csv not found"
            fi
            if [ -f gap.csv ]; then
              echo "**gapdown_above_100sma.csv (head):**"
              head -5 gap.csv
              echo ""
            else
              echo "⚠️ gapdown_above_100sma.csv not found"
            fi
          } >> "$GITHUB_STEP_SUMMARY"
