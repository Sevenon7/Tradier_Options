name: LEAPS Unified (produce + consume)

on:
  # Single UTC schedule; time-gate enforces 10:50 PT Â± WINDOW_MIN on weekdays
  schedule:
    - cron: "50 17,18 * * 1-5"
  workflow_dispatch:
    inputs:
      skip_time_gate:
        description: "Skip time gate (manual runs only)"
        required: false
        default: "false"
        type: choice
        options: ["false","true"]
      force_run:
        description: "Force producer even if today's data exists"
        required: false
        default: "false"
        type: choice
        options: ["false","true"]
      target_date:
        description: "Target YYYY-MM-DD (optional)"
        required: false
        type: string

concurrency:
  group: leaps-unified-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

permissions:
  contents: read

env:
  PYTHON_VERSION: "3.11"
  DESIRED_PT_TIME: "10:50"
  WINDOW_MIN: "95"
  REPO: "Sevenon7/Tradier_Options"
  BRANCH: "main"
  OWNER: "Sevenon7"
  DATA_RETENTION_DAYS: "30"

defaults:
  run:
    shell: bash

jobs:
  # =========================
  # 1) TIME GATE / INIT
  # =========================
  init-time-gate:
    runs-on: ubuntu-24.04
    timeout-minutes: 5
    outputs:
      run_ok: ${{ steps.tgate.outputs.run_ok }}
      date_dir: ${{ steps.setdate.outputs.date_dir }}
    steps:
      - name: Validate required secrets
        run: |
          if [ -z "${{ secrets.TRADIER_TOKEN }}" ]; then
            echo "::error::TRADIER_TOKEN secret is not configured"; exit 1; fi
          if [ -z "${{ secrets.GITHUB_TOKEN }}" ]; then
            echo "::error::GITHUB_TOKEN is not available"; exit 1; fi

      - name: Mask tokens early
        run: |
          echo "::add-mask::${{ secrets.TRADIER_TOKEN }}"
          echo "::add-mask::${{ secrets.GITHUB_TOKEN }}"

      - name: Resolve target date (UTC)
        id: setdate
        env:
          INPUT_DATE: ${{ github.event.inputs.target_date }}
        run: |
          set -euo pipefail
          if [ -n "${INPUT_DATE:-}" ]; then
            if ! date -d "${INPUT_DATE}" +%Y-%m-%d >/dev/null 2>&1; then
              echo "::error::Invalid date format: ${INPUT_DATE}"; exit 1
            fi
            DD="${INPUT_DATE}"
          else
            DD="$(date -u +%Y-%m-%d)"
          fi
          echo "date_dir=${DD}" >> "$GITHUB_OUTPUT"
          {
            echo "### ðŸš€ Workflow Initialization"
            echo "- Target date (UTC): \`${DD}\`"
            echo "- Trigger: ${{ github.event_name }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Time Gate (America/Los_Angeles)
        id: tgate
        env:
          SKIP_TG: ${{ github.event.inputs.skip_time_gate }}
        run: |
          set -euo pipefail
          SKIP_TG="${SKIP_TG:-false}"

          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${SKIP_TG}" = "true" ]; then
            echo "run_ok=true"  >> "$GITHUB_OUTPUT"
            echo "â­ï¸ Time gate skipped (manual override)" >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          export TZ=America/Los_Angeles
          NOW_PT="$(date +%H:%M)"
          DOW="$(date +%u)" # 1..7

          if [ "$DOW" -gt 5 ]; then
            echo "run_ok=false" >> "$GITHUB_OUTPUT"
            {
              echo "### â° Time Gate: BLOCKED"
              echo "- Reason: Weekend (day $DOW)"
              echo "- Now (PT): $NOW_PT"
            } >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          now_s="$(date -d "$NOW_PT" +%s)"
          tgt_s="$(date -d "${{ env.DESIRED_PT_TIME }}" +%s)"
          diff="$(( now_s - tgt_s ))"; [ "$diff" -lt 0 ] && diff="$(( -diff ))"
          delta="$(( diff / 60 ))"

          {
            echo "### â° Time Gate Check"
            echo "- Now (PT): $NOW_PT"
            echo "- Target (PT): ${{ env.DESIRED_PT_TIME }}"
            echo "- Delta: ${delta} min"
            echo "- Window: Â±${{ env.WINDOW_MIN }} min"
          } >> "$GITHUB_STEP_SUMMARY"

          if [ "$delta" -le "${{ env.WINDOW_MIN }}" ]; then
            echo "run_ok=true"  >> "$GITHUB_OUTPUT"
            echo "âœ… Within window â€” proceeding" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "run_ok=false" >> "$GITHUB_OUTPUT"
            echo "â¸ï¸ Outside window â€” skipping" >> "$GITHUB_STEP_SUMMARY"
          fi

  # =========================
  # 2) PRODUCER
  # =========================
  producer:
    needs: init-time-gate
    if: needs.init-time-gate.outputs.run_ok == 'true'
    runs-on: ubuntu-24.04
    timeout-minutes: 30
    permissions:
      contents: write
      pages: write
    outputs:
      produced_date: ${{ steps.collect.outputs.date_dir }}
      already: ${{ steps.skip.outputs.already }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system deps
        run: |
          set -euo pipefail
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends curl jq coreutils dos2unix
          sudo apt-get clean && sudo rm -rf /var/lib/apt/lists/*

      - name: Normalize line endings (guard)
        run: |
          set -euo pipefail
          find . -type f \( -name "*.sh" -o -name "*.py" \) -print0 | xargs -0 -r dos2unix

      - name: Setup Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Create requirements.txt (deterministic)
        run: |
          printf '%s\n' \
            'requests==2.32.3' \
            'pandas==2.2.2' \
            'numpy==1.26.4' \
            'python-dateutil==2.9.0.post0' > requirements.txt

      - name: Install Python deps (deterministic)
        env:
          PIP_DISABLE_PIP_VERSION_CHECK: "1"
          PIP_NO_INPUT: "1"
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt

      - name: Check if producer already ran
        id: skip
        env:
          DD: ${{ needs.init-time-gate.outputs.date_dir }}
          FORCE_RUN: ${{ github.event.inputs.force_run }}
        run: |
          set -euo pipefail
          FORCE_RUN="${FORCE_RUN:-false}"
          if [ "${FORCE_RUN}" = "true" ]; then
            echo "already=false" >> "$GITHUB_OUTPUT"
            echo "ðŸ”„ Force run enabled â€” ignoring existing data" >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi
          if [ -d "data/$DD" ] && [ -s "data/$DD/overlay_vwap_macd_rsi.csv" ]; then
            echo "already=true"  >> "$GITHUB_OUTPUT"
            echo "â­ï¸ Producer skipped â€” data present at data/$DD" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "already=false" >> "$GITHUB_OUTPUT"
            echo "âœ¨ Producer will generate to data/$DD" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Run main LEAPS script
        if: steps.skip.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -euo pipefail
          python leaps_batched_cached.py

      - name: Build Option P/L Analysis
        if: steps.skip.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -euo pipefail
          if [ -f tools/option_pl_builder.py ]; then
            python tools/option_pl_builder.py || echo "::warning::option_pl_builder.py failed (non-fatal)"
          fi

      - name: Enrich with VWAP data (imports tools/*)
        if: steps.skip.outputs.already == 'false'
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          set -euo pipefail
          if [ -f tools/enrich_overlay_with_vwap.py ]; then
            python tools/enrich_overlay_with_vwap.py --overlay overlay_vwap_macd_rsi.csv || \
              echo "::warning::VWAP enrichment failed (non-fatal)"
          fi

      - name: Validate produced files (soft)
        if: steps.skip.outputs.already == 'false'
        continue-on-error: true
        run: |
          python - <<'PY'
          import os, sys, pandas as pd
          errs=[]
          if not os.path.exists('overlay_vwap_macd_rsi.csv'): errs.append('overlay_vwap_macd_rsi.csv missing')
          else:
              try: pd.read_csv('overlay_vwap_macd_rsi.csv')
              except Exception as e: errs.append(f'overlay read error: {e}')
          for f in ['option_pl.csv','gapdown_above_100sma.csv']:
              if os.path.exists(f):
                  try: pd.read_csv(f)
                  except Exception as e: print(f'::warning::{f} read warn: {e}')
          [print(f'::error::{e}') for e in errs]
          sys.exit(1 if errs else 0)
          PY

      - name: Move artifacts into date dir (if new)
        if: steps.skip.outputs.already == 'false'
        id: collect
        env:
          TODAY_UTC: ${{ needs.init-time-gate.outputs.date_dir }}
        run: |
          set -euo pipefail
          DEST="data/${TODAY_UTC}"
          mkdir -p "${DEST}"
          for f in overlay_vwap_macd_rsi.csv option_pl.csv gapdown_above_100sma.csv vwap_missing.json; do
            [ -f "$f" ] && mv -f "$f" "${DEST}/"
          done
          echo "date_dir=${TODAY_UTC}" >> "$GITHUB_OUTPUT"

      - name: Build/refresh latest.json & analysis_digest.json
        if: steps.skip.outputs.already == 'false'
        env:
          TODAY_UTC: ${{ needs.init-time-gate.outputs.date_dir }}
          RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail
          jq -n --arg dd "${TODAY_UTC}" --arg ts "$(date -u +%Y-%m-%dT%H:%M:%SZ)" --arg run "$RUN_ID" \
            '{date_dir:("data/"+$dd),generated_utc:$ts,run_id:$run}' > latest.json
          python - <<'PY'
          import os, json, pandas as pd
          from datetime import datetime
          dd=os.environ["TODAY_UTC"]; base=f"data/{dd}"
          out={"date_dir":base,"generated_utc":datetime.utcnow().isoformat()+"Z","files":{}}
          def grab(p, cols=None):
              if not os.path.exists(p): return {"status":"missing"}
              try:
                  df=pd.read_csv(p); d={"status":"ok","rows":len(df),"columns":len(df.columns)}
                  if cols: d["preview"]=df[[c for c in cols if c in df.columns]].head(30).to_dict("records")
                  return d
              except Exception as e: return {"status":"error","error":str(e)}
          out["files"]["overlay"]=grab(f"{base}/overlay_vwap_macd_rsi.csv",
              ["Ticker","RSI14","MACD>Signal","VWAP","LastPx","Px_vs_VWAP","SMA100","Gap%","Guidance"])
          out["files"]["option_pl"]=grab(f"{base}/option_pl.csv")
          out["files"]["gap"]=grab(f"{base}/gapdown_above_100sma.csv")
          with open("analysis_digest.json","w") as f: json.dump(out,f,indent=2)
          PY

      - name: Commit artifacts (metadata always; data only when new)
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "LEAPS: artifacts for ${{ steps.collect.outputs.date_dir }}"
          branch: ${{ env.BRANCH }}
          add_options: "-A"
          file_pattern: |
            data/${{ steps.collect.outputs.date_dir }}/*
            latest.json
            analysis_digest.json

      - name: Prepare GitHub Pages payload
        if: steps.skip.outputs.already == 'false'
        run: |
          set -euo pipefail
          DD="${{ steps.collect.outputs.date_dir }}"
          rm -rf pages_pub
          mkdir -p pages_pub/data/"${DD}"
          cp -a "data/${DD}/." "pages_pub/data/${DD}/"
          cp -a latest.json analysis_digest.json pages_pub/

      - name: Deploy to GitHub Pages
        if: steps.skip.outputs.already == 'false'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: pages_pub
          keep_files: true
          enable_jekyll: false

      - name: Cleanup old data directories
        if: steps.skip.outputs.already == 'false'
        continue-on-error: true
        run: |
          set -euo pipefail
          [ -d data ] && find data -maxdepth 1 -type d -name "20*" -mtime +${DATA_RETENTION_DAYS} -print -exec rm -rf {} + || true

  # =========================
  # 3) CONSUMER
  # =========================
  consumer:
    needs: [init-time-gate, producer]
    if: needs.init-time-gate.outputs.run_ok == 'true'
    runs-on: ubuntu-24.04
    timeout-minutes: 12
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install system deps
        run: |
          set -euo pipefail
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends curl jq coreutils python3
          sudo apt-get clean && sudo rm -rf /var/lib/apt/lists/*

      - name: Make fetch tool executable
        run: |
          if [ -f tools/fetch.sh ]; then chmod +x tools/fetch.sh; else echo "::error::tools/fetch.sh missing"; exit 1; fi

      - name: Resolve effective date dir (prefer local latest.json; else newest â‰¤ today; else yesterday)
        id: datedir
        run: |
          set -euo pipefail
          TODAY="$(date -u +%Y-%m-%d)"
          CAND=""
          if [ -s latest.json ]; then
            PTR="$(jq -r '.date_dir // empty' latest.json | sed 's|^data/||')"
            if echo "${PTR}" | grep -Eq '^[0-9]{4}-[0-9]{2}-[0-9]{2}$'; then
              PTR_OK="$(TODAY="${TODAY}" PTR="${PTR}" python3 -c "import os,datetime; t=datetime.datetime.strptime(os.environ['TODAY'],'%Y-%m-%d'); p=datetime.datetime.strptime(os.environ['PTR'],'%Y-%m-%d'); print(os.environ['PTR'] if 0 <= (t-p).total_seconds()/3600.0 <= 24 else '')" 2>/dev/null || true)"
              if [ -n "${PTR_OK}" ]; then
                CAND="${PTR_OK}"
                echo "ðŸ“Œ Using latest.json pointer: ${CAND}" >> "$GITHUB_STEP_SUMMARY"
              fi
            fi
          fi
          if [ -z "${CAND}" ] && [ -d data ]; then
            CAND="$(find data -maxdepth 1 -type d -name '20*' -printf '%f\n' | sort | tail -1 || true)"
            [ -n "${CAND}" ] && echo "ðŸ“ Using newest directory: ${CAND}" >> "$GITHUB_STEP_SUMMARY"
          fi
          [ -z "${CAND}" ] && CAND="$(date -u -d 'yesterday' +%Y-%m-%d)"
          echo "date_dir=${CAND}" >> "$GITHUB_OUTPUT"
          {
            echo "### ðŸ“… Consumer Date Resolution"
            echo "- Selected Date: \`${CAND}\`"
            echo "- Today (UTC): \`${TODAY}\`"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Fetch overlay/PL/gap with fallback chain (Pages â†’ jsDelivr â†’ raw â†’ API)
        env:
          DD: ${{ steps.datedir.outputs.date_dir }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OWNER: ${{ env.OWNER }}
          REPO:  ${{ env.REPO }}
          BRANCH: ${{ env.BRANCH }}
        run: |
          set -euo pipefail
          found=0
          for p in overlay_vwap_macd_rsi.csv option_pl.csv gapdown_above_100sma.csv; do
            if [ -s "data/${DD}/${p}" ]; then cp "data/${DD}/${p}" "$(basename "$p" .csv).csv"; found=$((found+1)); fi
          done
          if [ $found -eq 0 ]; then
            tools/fetch.sh \
              "data/${DD}/overlay_vwap_macd_rsi.csv" overlay.csv \
              "data/${DD}/option_pl.csv"            option_pl.csv \
              "data/${DD}/gapdown_above_100sma.csv" gap.csv
          fi

      - name: Emit quick summary to Job Summary
        run: |
          {
            echo "### ðŸ“Š Consumer Data Summary"
            for f in overlay.csv option_pl.csv gap.csv; do
              if [ -s "$f" ]; then
                echo "#### $f"; echo '```csv'; head -5 "$f"; echo '```'
              fi
            done
          } >> "$GITHUB_STEP_SUMMARY"

  # =========================
  # 4) NOTIFY
  # =========================
  notify:
    needs: [init-time-gate, producer, consumer]
    if: always()
    runs-on: ubuntu-24.04
    steps:
      - name: Final status
        run: |
          {
            echo "## ðŸ“‹ Workflow Execution Summary"
            echo "| Job | Status |"
            echo "|---|---|"
            echo "| Time Gate | ${{ needs.init-time-gate.result }} |"
            echo "| Producer | ${{ needs.producer.result }} |"
            echo "| Consumer | ${{ needs.consumer.result }} |"
          } >> "$GITHUB_STEP_SUMMARY"
