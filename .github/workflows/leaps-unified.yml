name: LEAPS Unified (produce + consume)

on:
  schedule:
    # Single daily schedule in UTC. Time gate constrains to 10:50 PT ¬± window.
    - cron: "50 18 * * 1-5"
  workflow_dispatch:
    inputs:
      skip_time_gate:
        description: "Skip time gate (manual runs only)"
        required: false
        type: choice
        default: "false"
        options: ["false","true"]
      force_run:
        description: "Force producer even if today's data exists"
        required: false
        type: choice
        default: "false"
        options: ["false","true"]
      target_date:
        description: "Target YYYY-MM-DD (optional)"
        required: false
        type: string

concurrency:
  group: leaps-unified-${{ github.ref }}
  cancel-in-progress: false

permissions:
  contents: read

env:
  PYTHON_VERSION: "3.11"
  DESIRED_PT_TIME: "10:50"     # local PT target time
  WINDOW_MIN: "95"             # widen to straddle DST with one cron
  DATA_RETENTION_DAYS: "30"
  OWNER: "Sevenon7"
  REPO: "Sevenon7/Tradier_Options"
  BRANCH: "main"

defaults:
  run:
    shell: bash

# =========================
# 1) TIME GATE / INIT
# =========================
jobs:
  init-time-gate:
    runs-on: ubuntu-24.04
    timeout-minutes: 5
    permissions:
      contents: read
    outputs:
      run_ok:   ${{ steps.tgate.outputs.run_ok }}
      date_utc: ${{ steps.setdate.outputs.date_utc }}
    steps:
      - name: Validate required secrets
        run: |
          if [[ -z "${{ secrets.TRADIER_TOKEN }}" ]]; then
            echo "::error::Missing secret TRADIER_TOKEN"; exit 1; fi
          if [[ -z "${{ secrets.GITHUB_TOKEN }}" ]]; then
            echo "::error::Missing secret GITHUB_TOKEN"; exit 1; fi

      - name: Mask tokens
        run: |
          echo "::add-mask::${{ secrets.TRADIER_TOKEN }}"
          echo "::add-mask::${{ secrets.GITHUB_TOKEN }}"

      - name: Resolve UTC date (today or manual)
        id: setdate
        run: |
          set -euo pipefail
          IN="${{ github.event.inputs.target_date || '' }}"
          if [[ -n "$IN" ]]; then
            if ! date -d "$IN" +%Y-%m-%d >/dev/null 2>&1; then
              echo "::error::Invalid target_date: $IN"; exit 1; fi
            DD="$IN"
          else
            DD="$(date -u +%Y-%m-%d)"
          fi
          echo "date_utc=${DD}" >> "$GITHUB_OUTPUT"
          {
            echo "### üöÄ Init"
            echo "- **UTC date:** \`${DD}\`"
            echo "- **Trigger:** ${{ github.event_name }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Time Gate (America/Los_Angeles)
        id: tgate
        run: |
          set -euo pipefail

          # Manual override for dispatch
          if [[ "${{ github.event_name }}" == "workflow_dispatch" && "${{ github.event.inputs.skip_time_gate || 'false' }}" == "true" ]]; then
            echo "run_ok=true" >> "$GITHUB_OUTPUT"
            echo "‚è≠Ô∏è Time gate skipped (manual override)" >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          export TZ=America/Los_Angeles
          NOW_PT="$(date +%H:%M)"
          TGT_PT="${DESIRED_PT_TIME}"
          DOW="$(date +%u)"   # 1..7

          if [[ "$DOW" -gt 5 ]]; then
            echo "run_ok=false" >> "$GITHUB_OUTPUT"
            {
              echo "### ‚è∞ Time Gate"
              echo "- **Now (PT):** ${NOW_PT}"
              echo "- **Day:** $(date +%A)"
              echo "- **Status:** Weekend ‚Äî skip"
            } >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          now_s="$(date -d "$NOW_PT" +%s)"
          tgt_s="$(date -d "$TGT_PT" +%s)"
          diff="$((now_s - tgt_s))"; [[ $diff -lt 0 ]] && diff="$((-diff))"
          delta="$(( diff / 60 ))"

          {
            echo "### ‚è∞ Time Gate"
            echo "- **Now (PT):** ${NOW_PT}"
            echo "- **Target (PT):** ${TGT_PT}"
            echo "- **Delta:** ${delta} min"
            echo "- **Window:** ¬±${WINDOW_MIN} min"
          } >> "$GITHUB_STEP_SUMMARY"

          if [[ "$delta" -le "$WINDOW_MIN" ]]; then
            echo "run_ok=true" >> "$GITHUB_OUTPUT"
            echo "‚úÖ Within window ‚Äî proceed" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "run_ok=false" >> "$GITHUB_OUTPUT"
            echo "‚è∏Ô∏è Outside window ‚Äî skip" >> "$GITHUB_STEP_SUMMARY"
          fi

# =========================
# 2) PRODUCER
# =========================
  producer:
    needs: init-time-gate
    if: needs.init-time-gate.outputs.run_ok == 'true'
    runs-on: ubuntu-24.04
    timeout-minutes: 30
    permissions:
      contents: write
    outputs:
      dir:     ${{ steps.collect.outputs.dir }}
      already: ${{ steps.skip.outputs.already }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system deps
        run: |
          set -euo pipefail
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends curl jq coreutils dos2unix
          sudo apt-get clean && sudo rm -rf /var/lib/apt/lists/*

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Pin requirements (deterministic)
        run: |
          printf '%s\n' \
            'requests==2.32.3' \
            'pandas==2.2.2' \
            'numpy==1.26.4' \
            'python-dateutil==2.9.0.post0' > requirements.txt
          echo "### üì¶ Requirements" >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"
          cat requirements.txt >> "$GITHUB_STEP_SUMMARY"
          echo '```' >> "$GITHUB_STEP_SUMMARY"

      - name: Install Python deps
        env:
          PIP_DISABLE_PIP_VERSION_CHECK: "1"
          PIP_NO_INPUT: "1"
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt

      - name: Normalize line endings (guard against here-doc EOF)
        run: |
          set -euo pipefail
          find . -type f \( -name "*.sh" -o -name "*.py" -o -name "*.yml" \) -print0 | xargs -0 -I{} dos2unix {} || true

      - name: Check if producer already ran (UTC folder)
        id: skip
        run: |
          set -euo pipefail
          DD="${{ needs.init-time-gate.outputs.date_utc }}"
          if [[ "${{ github.event.inputs.force_run || 'false' }}" == "true" ]]; then
            echo "already=false" >> "$GITHUB_OUTPUT"
            echo "üîÑ Force run enabled" >> "$GITHUB_STEP_SUMMARY"
          elif [[ -s "data/${DD}/overlay_vwap_macd_rsi.csv" ]]; then
            echo "already=true" >> "$GITHUB_OUTPUT"
            echo "‚è≠Ô∏è Producer already completed for data/${DD}" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "already=false" >> "$GITHUB_OUTPUT"
            echo "‚ú® First run for data/${DD}" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Run main LEAPS script
        if: steps.skip.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -euo pipefail
          python leaps_batched_cached.py

      - name: Build Option P/L (optional)
        if: steps.skip.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -euo pipefail
          if [[ -f tools/option_pl_builder.py ]]; then
            python tools/option_pl_builder.py || echo "::warning ::option_pl_builder failed (non-fatal)"
          else
            echo "::notice ::tools/option_pl_builder.py not found"
          fi

      - name: Enrich overlay with intraday VWAP (PYTHONPATH set)
        if: steps.skip.outputs.already == 'false'
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          set -euo pipefail
          if [[ -f tools/enrich_overlay_with_vwap.py ]]; then
            python tools/enrich_overlay_with_vwap.py --overlay overlay_vwap_macd_rsi.csv || echo "::warning ::VWAP enrichment failed (non-fatal)"
          else
            echo "::notice ::tools/enrich_overlay_with_vwap.py not found"
          fi

      - name: Validate core artifact
        if: steps.skip.outputs.already == 'false'
        run: |
          set -euo pipefail
          test -s overlay_vwap_macd_rsi.csv || { echo "::error ::overlay_vwap_macd_rsi.csv missing"; exit 1; }

      - name: Move artifacts into data/<date>
        id: collect
        if: steps.skip.outputs.already == 'false'
        env:
          DD: ${{ needs.init-time-gate.outputs.date_utc }}
        run: |
          set -euo pipefail
          mkdir -p "data/${DD}"
          for f in overlay_vwap_macd_rsi.csv option_pl.csv gapdown_above_100sma.csv vwap_missing.json; do
            [[ -f "$f" ]] && mv -f "$f" "data/${DD}/"
          done
          echo "dir=${DD}" >> "$GITHUB_OUTPUT"
          echo "### üì¶ Artifacts (data/${DD})" >> "$GITHUB_STEP_SUMMARY"
          ls -lh "data/${DD}" || true

      - name: Commit data artifacts
        if: steps.skip.outputs.already == 'false'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          branch: ${{ env.BRANCH }}
          commit_message: "LEAPS data: data/${{ steps.collect.outputs.dir }}"
          file_pattern: data/${{ steps.collect.outputs.dir }}/*

      - name: Cleanup old data directories
        if: steps.skip.outputs.already == 'false'
        continue-on-error: true
        run: |
          set -euo pipefail
          if [[ -d data ]]; then
            find data -maxdepth 1 -type d -name '20*' -mtime +${DATA_RETENTION_DAYS} -print -exec rm -rf {} + || true
          fi

# =========================
# 3) PUBLISH (pointers + digest + Pages)
# =========================
  publish:
    needs: [init-time-gate, producer]
    if: needs.init-time-gate.outputs.run_ok == 'true'
    runs-on: ubuntu-24.04
    timeout-minutes: 15
    permissions:
      contents: write
      pages: write
    steps:
      - name: Checkout latest main
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0
          persist-credentials: true

      - name: Fast-forward to origin/main (avoid non-fast-forward)
        run: |
          set -euo pipefail
          git fetch origin main
          if ! git merge --ff-only origin/main; then
            echo "::warning ::Diverged; hard reset to origin/main"
            git reset --hard origin/main
          fi

      - name: Determine effective dir (must exist)
        id: eff
        env:
          PROD_DIR: ${{ needs.producer.outputs.dir }}
        run: |
          set -euo pipefail
          pick=""
          # Prefer producer's output if present
          if [[ -n "${PROD_DIR}" && -d "data/${PROD_DIR}" ]]; then
            pick="${PROD_DIR}"
          else
            today="$(date -u +%Y-%m-%d)"
            if [[ -d "data/${today}" ]]; then
              pick="${today}"
            else
              pick="$(find data -maxdepth 1 -type d -name '20*' -printf '%f\n' | sort | tail -1 || true)"
            fi
          fi
          if [[ -z "$pick" || ! -d "data/${pick}" ]]; then
            echo "::error ::No data/* directory found to publish"; exit 1; fi
          echo "dir=${pick}" >> "$GITHUB_OUTPUT"
          echo "üìÅ Effective publish dir: data/${pick}" >> "$GITHUB_STEP_SUMMARY"

      - name: Build latest.json + analysis_digest.json (no pandas)
        env:
          DDIR: ${{ steps.eff.outputs.dir }}
        run: |
          set -euo pipefail
          jq -n \
            --arg dd "data/${DDIR}" \
            --arg ts "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            '{date_dir:$dd, generated_utc:$ts}' > latest.json

          python3 - <<'PY'
          import os, csv, json
          dd = os.environ["DDIR"]
          base = f"data/{dd}"

          def meta(name, cols=None, n=30):
            p = f"{base}/{name}"
            if not os.path.exists(p):
              return {"status":"missing"}
            try:
              with open(p, newline='') as f:
                r = csv.DictReader(f)
                rows, sample = 0, []
                for row in r:
                  rows += 1
                  if len(sample) < n:
                    if cols:
                      sample.append({k: row.get(k) for k in cols})
                    else:
                      sample.append(row)
              return {"status":"ok","rows":rows,"columns":len(r.fieldnames or []),"preview":sample}
            except Exception as e:
              return {"status":"error","error":str(e)}

          digest = {"date_dir": base, "files": {}}
          digest["files"]["overlay"]   = meta("overlay_vwap_macd_rsi.csv",
                                              ["Ticker","RSI14","MACD>Signal","VWAP","LastPx","Px_vs_VWAP","SMA100","Gap%","Guidance"])
          digest["files"]["option_pl"] = meta("option_pl.csv")
          digest["files"]["gap"]       = meta("gapdown_above_100sma.csv")

          with open("analysis_digest.json","w") as f:
            json.dump(digest, f, indent=2)
          PY

      - name: Validate pointers & digest
        run: |
          set -euo pipefail
          test -s latest.json
          test -s analysis_digest.json
          jq -e '.date_dir' latest.json >/dev/null
          jq -e '.files.overlay' analysis_digest.json >/dev/null

      - name: Commit pointers + digest (main)
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          branch: main
          commit_message: "LEAPS: refresh pointers & digest (data/${{ steps.eff.outputs.dir }})"
          file_pattern: |
            latest.json
            analysis_digest.json
          push_options: --force-with-lease

      - name: Prepare Pages payload (data dir + pointers)
        run: |
          set -euo pipefail
          DD="${{ steps.eff.outputs.dir }}"
          rm -rf pages_pub
          mkdir -p "pages_pub/data/${DD}"
          cp -a "data/${DD}/." "pages_pub/data/${DD}/"
          cp latest.json analysis_digest.json pages_pub/

      - name: Publish to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: pages_pub
          keep_files: true
          enable_jekyll: false

# =========================
# 4) CONSUMER (optional verification)
# =========================
  consumer:
    # wait for publish so Pages has a chance to go live
    needs: [init-time-gate, producer, publish]
    if: needs.init-time-gate.outputs.run_ok == 'true'
    runs-on: ubuntu-24.04
    timeout-minutes: 12
    permissions:
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Ensure OS tools
        run: |
          set -euo pipefail
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends curl jq coreutils
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*

      # ‚¨áÔ∏è this replaces the brittle step that was failing
      - name: Verify published pointers (Pages ‚Üí jsDelivr ‚Üí raw; with retries)
        id: verify
        env:
          OWNER: ${{ github.repository_owner }}
          REPO_NAME: ${{ github.event.repository.name }}
          BRANCH: ${{ env.BRANCH }}
        run: |
          set -euo pipefail

          # tiny helper: fetch URL with exponential backoff; success if HTTP 200 and non-empty body
          fetch_json() {
            local url="$1"
            local out="$2"
            local delay=1
            for i in {1..8}; do
              code="$(curl -sS -L --connect-timeout 5 --max-time 15 -w '%{http_code}' -o "${out}" "${url}" || true)"
              if [[ "$code" == "200" && -s "${out}" ]]; then
                echo "OK ${url}"
                return 0
              fi
              sleep "$delay"
              delay=$(( delay < 10 ? delay*2 : 10 ))
            done
            echo "MISS ${url}"
            return 1
          }

          PAGES_URL="https://${OWNER}.github.io/${REPO_NAME}/latest.json"
          JSDL_URL="https://cdn.jsdelivr.net/gh/${OWNER}/${REPO_NAME}@${BRANCH}/latest.json"
          RAW_URL="https://raw.githubusercontent.com/${OWNER}/${REPO_NAME}/${BRANCH}/latest.json"

          SRC=""
          if fetch_json "${PAGES_URL}" ptr.json; then SRC="${PAGES_URL}";
          elif fetch_json "${JSDL_URL}" ptr.json; then SRC="${JSDL_URL}";
          elif fetch_json "${RAW_URL}"  ptr.json; then SRC="${RAW_URL}";
          fi

          DD=""
          if [[ -n "${SRC}" ]]; then
            # If jq fails, don't crash; just leave DD empty so we can fall back.
            DD="$(jq -r '.date_dir | sub("^data/";"") // empty' ptr.json 2>/dev/null || true)"
          fi

          # Fallback to newest directory in repo if pointer not available or wrong.
          if [[ -z "${DD}" || ! -d "data/${DD}" ]]; then
            FALLBACK="$(find data -maxdepth 1 -type d -name '20*' -printf '%f\n' | sort | tail -1 || true)"
            if [[ -n "${FALLBACK}" && -d "data/${FALLBACK}" ]]; then
              DD="${FALLBACK}"
              SRC="${SRC:-'repo fallback (newest dir)'}"
            fi
          fi

          if [[ -z "${DD}" ]]; then
            echo "::error::Could not resolve a valid date_dir from Pages/jsDelivr/raw and no local data directory was found."
            exit 1
          fi

          echo "date_dir=${DD}" >> "$GITHUB_OUTPUT"
          {
            echo "### üîé Consumer pointer resolution"
            echo "- Source used: ${SRC}"
            echo "- Resolved date_dir: \`${DD}\`"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Fetch overlay/PL/gap (Pages ‚Üí jsDelivr ‚Üí raw; then local)
        env:
          DD: ${{ steps.verify.outputs.date_dir }}
          OWNER: ${{ github.repository_owner }}
          REPO_NAME: ${{ github.event.repository.name }}
          BRANCH: ${{ env.BRANCH }}
        run: |
          set -euo pipefail

          pull_one() {
            local rel="$1" dst="$2"
            local pages="https://${OWNER}.github.io/${REPO_NAME}/${rel}"
            local jsdl="https://cdn.jsdelivr.net/gh/${OWNER}/${REPO_NAME}@${BRANCH}/${rel}"
            local raw="https://raw.githubusercontent.com/${OWNER}/${REPO_NAME}/${BRANCH}/${rel}"

            for u in "$pages" "$jsdl" "$raw"; do
              if curl -fLsS "$u" -o "$dst"; then
                echo "Fetched $rel from $u"
                return 0
              fi
            done
            # final local fallback
            if [[ -s "$rel" ]]; then
              cp "$rel" "$dst"
              echo "Copied local $rel"
              return 0
            fi
            return 1
          }

          mkdir -p work
          pull_one "data/${DD}/overlay_vwap_macd_rsi.csv" work/overlay.csv
          pull_one "data/${DD}/option_pl.csv"            work/option_pl.csv || true
          pull_one "data/${DD}/gapdown_above_100sma.csv" work/gap.csv       || true

          # basic validation
          if [[ ! -s work/overlay.csv ]]; then
            echo "::error::overlay.csv is missing/empty after fetch attempts"
            exit 1
          fi

          {
            echo "### üìä Consumer fetch summary"
            for f in overlay.csv option_pl.csv gap.csv; do
              if [[ -s "work/$f" ]]; then
                rows=$(tail -n +2 "work/$f" | wc -l | tr -d ' ')
                size=$(stat -c%s "work/$f")
                echo "- $f: ${rows} rows, ${size} bytes"
              else
                echo "- $f: (missing)"
              fi
            done
          } >> "$GITHUB_STEP_SUMMARY"

# =========================
# 5) NOTIFY
# =========================
  notify:
    needs: [init-time-gate, producer, publish, consumer]
    if: always()
    runs-on: ubuntu-24.04
    steps:
      - name: Final status
        run: |
          {
            echo "## üìã Workflow Summary"
            echo ""
            echo "| Job | Result |"
            echo "|-----|--------|"
            echo "| init-time-gate | ${{ needs.init-time-gate.result }} |"
            echo "| producer       | ${{ needs.producer.result }} |"
            echo "| publish        | ${{ needs.publish.result }} |"
            echo "| consumer       | ${{ needs.consumer.result }} |"
            echo ""
            if [[ "${{ needs.publish.result }}" == "success" ]]; then
              if [[ -f latest.json ]]; then
                echo "- latest.json ‚Üí \`$(jq -r '.date_dir' latest.json)\`"
              fi
            fi
          } >> "$GITHUB_STEP_SUMMARY"
