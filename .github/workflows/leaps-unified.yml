name: LEAPS Unified (produce + consume)

on:
  # Run at both UTC times; time-gate picks the right one (handles DST)
  schedule:
    # PDT (Mar‚ÄìOct): 12:35 PT == 19:35 UTC
    - cron: '35 19 * 3-10 1-5'
    # PST (Nov‚ÄìFeb): 12:35 PT == 20:35 UTC
    - cron: '35 20 * 11,12,1,2 1-5'
  workflow_dispatch:
    inputs:
      skip_time_gate:
        description: 'Skip time-gate (manual runs)'
        required: false
        default: false
        type: boolean
      debug_mode:
        description: 'Enable debug logging'
        required: false
        default: false
        type: boolean
      force_run:
        description: 'Force run even if today already produced'
        required: false
        default: false
        type: boolean
      target_date:
        description: 'Override date (YYYY-MM-DD)'
        required: false
        type: string

concurrency:
  group: leaps-unified-${{ github.ref }}
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  issues: write

env:
  PYTHON_VERSION: "3.11"
  DESIRED_PT_TIME: "12:35"     # <‚Äî new target
  WINDOW_MIN: "35"
  OWNER: "Sevenon7"
  REPO: "Sevenon7/Tradier_Options"
  BRANCH: "main"
  DATA_RETENTION_DAYS: "30"
  MAX_RETRY_ATTEMPTS: "3"
  # Make sure Python sees repo-root for `tools.*` imports
  PYTHONPATH: ${{ github.workspace }}
  # Public mirrors (used by fetch.sh, consumer)
  PAGES_BASE: "https://sevenon7.github.io/Tradier_Options"
  JSDELIVR_BASE: "https://cdn.jsdelivr.net/gh/Sevenon7/Tradier_Options@main"
  RAW_BASE: "https://raw.githubusercontent.com/Sevenon7/Tradier_Options/main"

jobs:
  initialize:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      run_ok: ${{ steps.tgate.outputs.run_ok }}
      date_dir: ${{ steps.set_date.outputs.date_dir }}
      cache_key: ${{ steps.cache_key.outputs.key }}
    steps:
      - name: Mask sensitive data
        run: |
          echo "::add-mask::${{ secrets.TRADIER_TOKEN }}"
          echo "::add-mask::${{ secrets.GITHUB_TOKEN }}"

      - name: Set target date
        id: set_date
        shell: bash
        run: |
          if [[ -n "${{ github.event.inputs.target_date }}" ]]; then
            DATE_DIR="${{ github.event.inputs.target_date }}"
          else
            DATE_DIR="$(date -u +%Y-%m-%d)"
          fi
          echo "date_dir=${DATE_DIR}" >> "$GITHUB_OUTPUT"
          echo "üìÖ Target date: ${DATE_DIR}" >> "$GITHUB_STEP_SUMMARY"

      - name: Generate cache key
        id: cache_key
        run: |
          WEEK=$(date -u +%Y-%W)
          echo "key=deps-${WEEK}-${{ env.PYTHON_VERSION }}" >> "$GITHUB_OUTPUT"

      - name: Time Gate (America/Los_Angeles)
        id: tgate
        shell: bash
        run: |
          set -euo pipefail
          if [[ "${{ github.event_name }}" == "workflow_dispatch" && "${{ github.event.inputs.skip_time_gate }}" == "true" ]]; then
            echo "run_ok=true" >> "$GITHUB_OUTPUT"
            echo "‚è≠Ô∏è Time-gate skipped (manual override)" >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi
          export TZ=America/Los_Angeles
          NOW_PT="$(date +%H:%M)"
          TARGET_PT="${DESIRED_PT_TIME}"
          now_s="$(date -d "$NOW_PT" +%s)"
          tgt_s="$(date -d "$TARGET_PT" +%s)"
          diff="$(( now_s - tgt_s ))"; [ "$diff" -lt 0 ] && diff="$(( -diff ))"
          DELTA="$(( diff / 60 ))"
          if [ "${DELTA}" -le "${WINDOW_MIN}" ]; then
            echo "run_ok=true"  >> "$GITHUB_OUTPUT"
            echo "‚úÖ Within window: ${NOW_PT} ~ ${TARGET_PT}" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "run_ok=false" >> "$GITHUB_OUTPUT"
            echo "‚è∏Ô∏è Outside window: ${NOW_PT} vs ${TARGET_PT}" >> "$GITHUB_STEP_SUMMARY"
          fi

  producer:
    needs: initialize
    if: needs.initialize.outputs.run_ok == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      date_dir: ${{ needs.initialize.outputs.date_dir }}
      already_ran: ${{ steps.skipcheck.outputs.already }}
      artifacts_created: ${{ steps.validate.outputs.valid }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Setup Python
        uses: actions/setup-python@v5
        with: { python-version: ${{ env.PYTHON_VERSION }} }

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ needs.initialize.outputs.cache_key }}
          restore-keys: |
            deps-${{ env.PYTHON_VERSION }}-

      - name: Install system deps
        run: |
          set -euo pipefail
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends curl jq coreutils
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*

      - name: Install Python deps
        run: |
          set -euo pipefail
          printf '%s\n' \
            'requests==2.31.0' \
            'pandas==2.1.4' \
            'numpy==1.26.2' \
            'python-dateutil==2.8.2' > requirements.txt
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt

      - name: Skip if already ran today (UTC)
        id: skipcheck
        shell: bash
        run: |
          set -euo pipefail
          DATE_DIR="data/${{ needs.initialize.outputs.date_dir }}"
          if [[ "${{ github.event.inputs.force_run }}" == "true" ]]; then
            echo "already=false" >> "$GITHUB_OUTPUT"
            echo "üîÑ Force run enabled" >> "$GITHUB_STEP_SUMMARY"
          elif [ -d "$DATE_DIR" ] && [ -f "$DATE_DIR/overlay_vwap_macd_rsi.csv" ]; then
            echo "already=true" >> "$GITHUB_OUTPUT"
            echo "‚è≠Ô∏è Producer already completed for $DATE_DIR" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "already=false" >> "$GITHUB_OUTPUT"
            echo "‚ú® First run for $DATE_DIR ‚Äî executing Producer" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Run main LEAPS script
        if: steps.skipcheck.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -euo pipefail
          a=1; max=${MAX_RETRY_ATTEMPTS}
          while [ $a -le $max ]; do
            echo "Run leaps_batched_cached.py attempt $a/$max"
            if python leaps_batched_cached.py; then
              break
            fi
            [ $a -eq $max ] && exit 1
            sleep 30; a=$((a+1))
          done

      - name: Build Actual Option P/L (fallback-safe)
        if: steps.skipcheck.outputs.already == 'false'
        env: { TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }} }
        run: |
          if [ -f tools/option_pl_builder.py ]; then
            python tools/option_pl_builder.py || echo "‚ö†Ô∏è option_pl_builder failed (continuing)"
          else
            echo "‚ö†Ô∏è tools/option_pl_builder.py not found"
          fi

      - name: Enrich overlay with intraday VWAP (PYTHONPATH set)
        if: steps.skipcheck.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          if [ -f tools/enrich_overlay_with_vwap.py ]; then
            python tools/enrich_overlay_with_vwap.py --overlay overlay_vwap_macd_rsi.csv || echo "‚ö†Ô∏è VWAP enrichment failed (non-fatal)"
          fi

      - name: Validate produced data
        if: steps.skipcheck.outputs.already == 'false'
        id: validate
        continue-on-error: true
        run: |
          python - <<'PY'
          import os, pandas as pd, json
          ok = False; errs=[]
          if os.path.exists('overlay_vwap_macd_rsi.csv'):
              try:
                  df = pd.read_csv('overlay_vwap_macd_rsi.csv')
                  ok = len(df) > 0
              except Exception as e:
                  errs.append(f"overlay parse: {e}")
          else:
              errs.append("overlay missing")
          with open('validation_report.json','w') as f: json.dump({"ok":ok,"errs":errs}, f)
          print(f"valid={ok}")
          PY
          # export a simple flag
          if jq -e '.ok==true' validation_report.json >/dev/null 2>&1; then
            echo "valid=true" >> "$GITHUB_OUTPUT"
          else
            echo "valid=false" >> "$GITHUB_OUTPUT"

      - name: Collect artifacts into date dir + update latest.json + analysis_digest.json
        if: steps.skipcheck.outputs.already == 'false'
        id: collect
        shell: bash
        run: |
          set -euo pipefail
          TODAY="${{ needs.initialize.outputs.date_dir }}"
          DD="data/${TODAY}"
          mkdir -p "$DD"
          # Move root artifacts into date folder
          for f in overlay_vwap_macd_rsi.csv option_pl.csv gapdown_above_100sma.csv vwap_missing.json validation_report.json; do
            [ -f "$f" ] && mv -f "$f" "$DD/"
          done

          # latest.json at repo root (points to date_dir)
          jq -n --arg dd "$DD" --arg ts "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            '{date_dir:$dd, timestamp:$ts}' > latest.json

          # analysis_digest.json at repo root (small preview + counts)
          python - <<'PY'
          import os, json, pandas as pd
          dd=os.environ["TODAY"]; base=f"data/{dd}"
          dig={"date_dir":base}
          def head(path, cols=None, n=20):
              p=f"{base}/{path}"
              if not os.path.exists(p): return None
              try:
                  df=pd.read_csv(p)
                  if cols: df=df[[c for c in cols if c in df.columns]]
                  return df.head(n).to_dict(orient="records")
              except Exception as e:
                  return {"error":str(e)}
          dig["overlay_preview"]=head("overlay_vwap_macd_rsi.csv",
            ["Ticker","RSI14","MACD>Signal","VWAP","LastPx","Px_vs_VWAP","SMA100","Gap%","Guidance"], 30)
          for nm in ("option_pl.csv","gapdown_above_100sma.csv"):
              p=f"{base}/{nm}"
              if os.path.exists(p):
                  try:
                      dig[nm.replace('.csv','_rows')]=int(pd.read_csv(p).shape[0])
                  except Exception as e:
                      dig[nm+"_error"]=str(e)
          with open("analysis_digest.json","w") as f: json.dump(dig,f,indent=2)
          PY

          echo "date_dir=${TODAY}" >> "$GITHUB_OUTPUT"

      - name: Commit artifacts to repo
        if: steps.skipcheck.outputs.already == 'false'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "üìä LEAPS daily overlay - ${{ needs.initialize.outputs.date_dir }}"
          branch: ${{ env.BRANCH }}
          add_options: -A
          file_pattern: 'data/* latest.json analysis_digest.json'

      - name: Publish mirror to gh-pages (data dir + root digest files)
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: public
          keep_files: true
        run: |
          set -euo pipefail
          TODAY="${{ needs.initialize.outputs.date_dir }}"
          mkdir -p public/data/${TODAY}
          cp -R data/${TODAY}/* public/data/${TODAY}/ 2>/dev/null || true
          # include root pointers in Pages root
          cp -f latest.json analysis_digest.json public/
          echo "Publishing:"
          find public -maxdepth 2 -type f | sed 's/^/ - /'

  consumer:
    needs: [initialize, producer]
    if: needs.initialize.outputs.run_ok == 'true' && !cancelled()
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Ensure OS tools
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl jq coreutils
          chmod +x tools/fetch.sh

      - name: Resolve date_dir via Pages/jsDelivr/raw (latest.json)
        id: datedir
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p tmp
          # Try Pages ‚Üí jsDelivr ‚Üí raw for latest.json
          tools/fetch.sh latest.json tmp/latest.json || true
          if [ -s tmp/latest.json ]; then
            DATE_DIR="$(jq -r '.date_dir // empty' tmp/latest.json | sed 's|^data/||')"
          fi
          # Fallback: pick newest data folder locally
          if [ -z "${DATE_DIR:-}" ]; then
            DATE_DIR="$(find data -maxdepth 1 -type d -name '20*' | sort -r | head -1 | xargs -I{} basename {} || true)"
          fi
          # Final fallback: today UTC
          if [ -z "${DATE_DIR:-}" ]; then
            DATE_DIR="$(date -u +%Y-%m-%d)"
          fi
          echo "date_dir=${DATE_DIR}" >> "$GITHUB_OUTPUT"
          echo "Resolved date_dir: ${DATE_DIR}" >> "$GITHUB_STEP_SUMMARY"

      - name: Fetch overlay/PL/gap with fallback chain (Pages ‚Üí jsDelivr ‚Üí raw)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail
          DD="${{ steps.datedir.outputs.date_dir }}"
          tools/fetch.sh \
            "data/${DD}/overlay_vwap_macd_rsi.csv" overlay.csv \
            "data/${DD}/option_pl.csv"            option_pl.csv \
            "data/${DD}/gapdown_above_100sma.csv" gap.csv

      - name: Emit quick summary
        run: |
          {
            echo "### LEAPS (Consumer)"
            echo "- date_dir: ${{ steps.datedir.outputs.date_dir }}"
            echo ""
            echo "overlay.csv (head):"; head -5 overlay.csv || true
            echo ""; echo "option_pl.csv (head):"; head -5 option_pl.csv || true
            echo ""; echo "gap.csv (head):"; head -5 gap.csv || true
          } >> "$GITHUB_STEP_SUMMARY"

  notify:
    needs: [initialize, producer, consumer]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Summarize status
        id: status
        run: |
          if [[ "${{ needs.producer.result }}" == "failure" || "${{ needs.consumer.result }}" == "failure" ]]; then
            echo "status=failed" >> "$GITHUB_OUTPUT"
          elif [[ "${{ needs.producer.result }}" == "skipped" && "${{ needs.consumer.result }}" == "skipped" ]]; then
            echo "status=skipped" >> "$GITHUB_OUTPUT"
          else
            echo "status=success" >> "$GITHUB_OUTPUT"
          fi

      - name: File issue on failure (notification)
        if: steps.status.outputs.status == 'failed' && github.event_name != 'workflow_dispatch'
        uses: actions/github-script@v7
        with:
          script: |
            const date = new Date().toISOString().slice(0,10);
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Workflow Failure: LEAPS Unified - ${date}`,
              body: `Daily LEAPS workflow failed.\n\nRun: ${runUrl}`,
              labels: ['workflow-failure','automated']
            });

      - name: Final summary
        run: |
          {
            echo "## Workflow Summary"
            echo "- Status: ${{ steps.status.outputs.status }}"
            echo "- Producer: ${{ needs.producer.result }}"
            echo "- Consumer: ${{ needs.consumer.result }}"
            echo "- Trigger: ${{ github.event_name }}"
          } >> "$GITHUB_STEP_SUMMARY"
