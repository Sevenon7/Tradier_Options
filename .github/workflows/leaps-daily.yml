name: LEAPS Daily Overlay

on:
  # 11:00 AM PT ≈ 18:00 UTC (DST) and 19:00 UTC (Standard)
  schedule:
    - cron: '0 18 * * 1-5'
    - cron: '0 19 * * 1-5'
  workflow_dispatch: {}

# Prevent overlapping runs for this workflow on the same ref
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  run-overlay:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas

      - name: Mask token (extra safety)
        if: ${{ secrets.TRADIER_TOKEN != '' }}
        run: echo "::add-mask::${{ secrets.TRADIER_TOKEN }}"

      # Guard: skip second cron if today's folder already exists
      - name: Skip if already ran today
        id: skipcheck
        shell: bash
        run: |
          DATE_DIR="data/$(date -u +%Y-%m-%d)"
          if [ -d "$DATE_DIR" ]; then
            echo "already=true" >> "$GITHUB_OUTPUT"
            echo "Run already completed for $DATE_DIR — skipping."
          else
            echo "already=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Run overlay script (Tradier)
        if: steps.skipcheck.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -eo pipefail
          python leaps_batched_cached.py

      - name: Prepare dated folder & move outputs (atomic already in script)
        if: steps.skipcheck.outputs.already == 'false'
        id: stamp
        shell: bash
        run: |
          DATE_DIR="data/$(date -u +%Y-%m-%d)"
          mkdir -p "$DATE_DIR"
          [ -f overlay_vwap_macd_rsi.csv ] && mv overlay_vwap_macd_rsi.csv "$DATE_DIR/overlay_vwap_macd_rsi.csv" || touch "$DATE_DIR/overlay_vwap_macd_rsi.csv"
          [ -f option_pl.csv ]               && mv option_pl.csv               "$DATE_DIR/option_pl.csv"               || touch "$DATE_DIR/option_pl.csv"
          [ -f gapdown_above_100sma.csv ]    && mv gapdown_above_100sma.csv    "$DATE_DIR/gapdown_above_100sma.csv"    || touch "$DATE_DIR/gapdown_above_100sma.csv"
          printf "# LEAPS Overlay (%s UTC)\n\nArtifacts:\n- overlay_vwap_macd_rsi.csv\n- option_pl.csv\n- gapdown_above_100sma.csv\n" "$(date -u)" > "$DATE_DIR/SUMMARY.md"
          echo "date_dir=$DATE_DIR" >> "$GITHUB_OUTPUT"

      - name: Compute RAW URLs (for easy copy/paste)
        if: steps.skipcheck.outputs.already == 'false'
        id: raw
        shell: bash
        run: |
          REPO="${{ github.repository }}"
          DATE_DIR="${{ steps.stamp.outputs.date_dir }}"
          echo "raw_overlay=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/overlay_vwap_macd_rsi.csv" >> "$GITHUB_OUTPUT"
          echo "raw_pl=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/option_pl.csv" >> "$GITHUB_OUTPUT"
          echo "raw_gap=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/gapdown_above_100sma.csv" >> "$GITHUB_OUTPUT"

      # Emit JSON digest into the Job Summary for easy copy/paste to ChatGPT
      - name: Build JSON digest for ChatGPT (adds to Summary)
        if: steps.skipcheck.outputs.already == 'false'
        env:
          DATE_DIR: ${{ steps.stamp.outputs.date_dir }}
          RAW_OVERLAY: ${{ steps.raw.outputs.raw_overlay }}
          RAW_PL: ${{ steps.raw.outputs.raw_pl }}
          RAW_GAP: ${{ steps.raw.outputs.raw_gap }}
        run: |
          python - << 'PY'
          import os, json, pandas as pd

          date_dir = os.environ["DATE_DIR"]
          raw_overlay = os.environ.get("RAW_OVERLAY","")
          raw_pl = os.environ.get("RAW_PL","")
          raw_gap = os.environ.get("RAW_GAP","")
          summary_path = os.environ.get("GITHUB_STEP_SUMMARY")

          def read_csv(path):
              try:
                  return pd.read_csv(path)
              except Exception:
                  return pd.DataFrame()

          ov = read_csv(f"{date_dir}/overlay_vwap_macd_rsi.csv")
          pl = read_csv(f"{date_dir}/option_pl.csv")
          gp = read_csv(f"{date_dir}/gapdown_above_100sma.csv")

          keep_ov = ["Ticker","RSI14","MACD>Signal","VWAP","LastPx","Px_vs_VWAP","SMA100","Gap%","Guidance"]
          ov = ov[[c for c in keep_ov if c in ov.columns]].copy()

          keep_pl = ["Contract","OCC","Bid","Ask","Last","MidUsed","Entry","Contracts","P/L($)","P/L(%)","IV"]
          pl = pl[[c for c in keep_pl if c in pl.columns]].copy()

          keep_gp = ["Ticker","Gap%","Close","SMA100"]
          gp = gp[[c for c in keep_gp if c in gp.columns]].copy()

          # JSON-safe (no NaN/Inf)
          def _clean(df):
              return json.loads(df.to_json(orient="records"))

          digest = {
              "raw_links": {
                  "overlay": raw_overlay,
                  "option_pl": raw_pl,
                  "gap_screen": raw_gap
              },
              "overlay": _clean(ov),
              "option_pl": _clean(pl),
              "gap_screen": _clean(gp)
          }

          block = "```json\n" + json.dumps(digest, indent=2) + "\n```"
          print(block)
          if summary_path:
              with open(summary_path, "a", encoding="utf-8") as f:
                  f.write("### JSON Digest for ChatGPT\n\n")
                  f.write(block + "\n")
          PY

      - name: Append RAW links to job summary
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          {
            echo "### Raw CSV links (UTC $(date -u))"
            echo "- ${{ steps.raw.outputs.raw_overlay }}"
            echo "- ${{ steps.raw.outputs.raw_pl }}"
            echo "- ${{ steps.raw.outputs.raw_gap }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Commit results to repo
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          set -eo pipefail
          git config user.name  "${{ github.actor }}"
          git config user.email "${{ github.actor }}@users.noreply.github.com"
          git add "${{ steps.stamp.outputs.date_dir }}"
          git commit -m "LEAPS overlay auto-run: ${{ steps.stamp.outputs.date_dir }}"
          git push

      - name: Upload artifacts
        if: steps.skipcheck.outputs.already == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: leaps-report
          path: |
            ${{ steps.stamp.outputs.date_dir }}/overlay_vwap_macd_rsi.csv
            ${{ steps.stamp.outputs.date_dir }}/option_pl.csv
            ${{ steps.stamp.outputs.date_dir }}/gapdown_above_100sma.csv
            ${{ steps.stamp.outputs.date_dir }}/SUMMARY.md
          if-no-files-found: warn
          

      # --- OPTIONAL: Mirror to Google Drive (uncomment and add secrets to use) ---
      # - name: Install rclone
      #   if: steps.skipcheck.outputs.already == 'false'
      #   run: |
      #     sudo apt-get update -y
      #     sudo apt-get install -y unzip
      #     curl -L https://downloads.rclone.org/rclone-current-linux-amd64.zip -o rclone.zip
      #     unzip -q rclone.zip
      #     sudo cp rclone-*-linux-amd64/rclone /usr/local/bin/rclone
      #
      # - name: Configure rclone for Google Drive (service account)
      #   if: steps.skipcheck.outputs.already == 'false'
      #   run: |
      #     echo '${{ secrets.GDRIVE_SA_JSON }}' > sa.json
      #     printf "[gdrive]\n" > rclone.conf
      #     printf "type = drive\n" >> rclone.conf
      #     printf "scope = drive\n" >> rclone.conf
      #     printf "service_account_file = %s/sa.json\n" "${{ github.workspace }}" >> rclone.conf
      #
      # - name: Upload today's CSVs to Google Drive
      #   if: steps.skipcheck.outputs.already == 'false'
      #   env:
      #     RCLONE_CONFIG: ${{ github.workspace }}/rclone.conf
      #   run: |
      #     DATE_DIR="${{ steps.stamp.outputs.date_dir }}"
      #     rclone copy "$DATE_DIR" gdrive: --drive-root-folder-id "${{ secrets.GDRIVE_FOLDER_ID }}" -v
