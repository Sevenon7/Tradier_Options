name: LEAPS Daily Overlay

on:
  # 11:00 AM PT ≈ 18:00 UTC (DST) and 19:00 UTC (Standard). Guard duplicates below.
  schedule:
    - cron: '0 18 * * 1-5'  # PDT (roughly Mar–Nov)
    - cron: '0 19 * * 1-5'  # PST (roughly Nov–Mar)
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  run-overlay:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas

      # Avoid double-runs on DST crossover days
      - name: Skip if already ran today
        id: skipcheck
        run: |
          DATE_DIR="data/$(date -u +%Y-%m-%d)"
          if [ -d "$DATE_DIR" ]; then
            echo "already=true" >> $GITHUB_OUTPUT
            echo "Run already completed for $DATE_DIR — skipping."
          else
            echo "already=false" >> $GITHUB_OUTPUT

      - name: Run overlay script (Tradier)
        if: steps.skipcheck.outputs.already == 'false'
        env:
          TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}
        run: |
          set -eo pipefail
          python leaps_batched_cached.py

      - name: Prepare dated folder & move outputs
        if: steps.skipcheck.outputs.already == 'false'
        id: stamp
        run: |
          set -eo pipefail
          DATE_DIR="data/$(date -u +%Y-%m-%d)"
          mkdir -p "$DATE_DIR"
          [ -f overlay_vwap_macd_rsi.csv ] && mv overlay_vwap_macd_rsi.csv "$DATE_DIR/overlay_vwap_macd_rsi.csv" || touch "$DATE_DIR/overlay_vwap_macd_rsi.csv"
          [ -f option_pl.csv ]               && mv option_pl.csv               "$DATE_DIR/option_pl.csv"               || touch "$DATE_DIR/option_pl.csv"
          [ -f gapdown_above_100sma.csv ]    && mv gapdown_above_100sma.csv    "$DATE_DIR/gapdown_above_100sma.csv"    || touch "$DATE_DIR/gapdown_above_100sma.csv"
          printf "# LEAPS Overlay (%s UTC)\n\nArtifacts:\n- overlay_vwap_macd_rsi.csv\n- option_pl.csv\n- gapdown_above_100sma.csv\n" "$(date -u)" > "$DATE_DIR/SUMMARY.md"
          echo "date_dir=$DATE_DIR" >> $GITHUB_OUTPUT

      - name: Compute RAW URLs
        if: steps.skipcheck.outputs.already == 'false'
        id: raw
        run: |
          REPO="${{ github.repository }}"
          DATE_DIR="${{ steps.stamp.outputs.date_dir }}"
          echo "raw_overlay=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/overlay_vwap_macd_rsi.csv" >> $GITHUB_OUTPUT
          echo "raw_pl=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/option_pl.csv" >> $GITHUB_OUTPUT
          echo "raw_gap=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/gapdown_above_100sma.csv" >> $GITHUB_OUTPUT

      # NEW: Emit a compact JSON digest to the job summary for easy copy/paste here
      - name: Build JSON digest for ChatGPT
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          python - << 'PY'
          import os, json, pandas as pd
          d = os.environ["DATE_DIR"] if "DATE_DIR" in os.environ else "${{ steps.stamp.outputs.date_dir }}"
          def read_csv(path):
              try: return pd.read_csv(path)
              except Exception: return pd.DataFrame()
          ov = read_csv(f"{d}/overlay_vwap_macd_rsi.csv")
          pl = read_csv(f"{d}/option_pl.csv")
          gp = read_csv(f"{d}/gapdown_above_100sma.csv")

          # keep only relevant columns (and normalize names if needed)
          keep_ov = ["Ticker","RSI14","MACD>Signal","VWAP","LastPx","Px_vs_VWAP","SMA100","Gap%","Guidance"]
          ov = ov[[c for c in keep_ov if c in ov.columns]].copy()

          keep_pl = ["Contract","OCC","Bid","Ask","Last","MidUsed","Entry","Contracts","P/L($)","P/L(%)","IV"]
          pl = pl[[c for c in keep_pl if c in pl.columns]].copy()

          keep_gp = ["Ticker","Gap%","Close","SMA100"]
          gp = gp[[c for c in keep_gp if c in gp.columns]].copy()

          digest = {
            "raw_links": {
              "overlay": "${{ steps.raw.outputs.raw_overlay }}",
              "option_pl": "${{ steps.raw.outputs.raw_pl }}",
              "gap_screen": "${{ steps.raw.outputs.raw_gap }}"
            },
            "overlay": ov.to_dict(orient="records"),
            "option_pl": pl.to_dict(orient="records"),
            "gap_screen": gp.to_dict(orient="records"),
          }
          print("```json")
          print(json.dumps(digest, indent=2))
          print("```")
          PY

      - name: Append RAW links to summary
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          {
            echo "### Raw CSV links (UTC $(date -u))"
            echo "- ${{ steps.raw.outputs.raw_overlay }}"
            echo "- ${{ steps.raw.outputs.raw_pl }}"
            echo "- ${{ steps.raw.outputs.raw_gap }}"
          } >> $GITHUB_STEP_SUMMARY

      - name: Commit results to repo
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          set -eo pipefail
          git config user.name  "${{ github.actor }}"
          git config user.email "${{ github.actor }}@users.noreply.github.com"
          git add ${{ steps.stamp.outputs.date_dir }}
          git commit -m "LEAPS overlay auto-run: ${{ steps.stamp.outputs.date_dir }}"
          git push

      - name: Upload artifacts
        if: steps.skipcheck.outputs.already == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: leaps-report
          path: |
            ${{ steps.stamp.outputs.date_dir }}/overlay_vwap_macd_rsi.csv
            ${{ steps.stamp.outputs.date_dir }}/option_pl.csv
            ${{ steps.stamp.outputs.date_dir }}/gapdown_above_100sma.csv
            ${{ steps.stamp.outputs.date_dir }}/SUMMARY.md

      # --- OPTIONAL: Mirror to Google Drive (uncomment and add secrets to use) ---
      # - name: Install rclone
      #   if: steps.skipcheck.outputs.already == 'false'
      #   run: |
      #     sudo apt-get update -y
      #     sudo apt-get install -y unzip
      #     curl -L https://downloads.rclone.org/rclone-current-linux-amd64.zip -o rclone.zip
      #     unzip -q rclone.zip
      #     sudo cp rclone-*-linux-amd64/rclone /usr/local/bin/rclone
      #
      # - name: Configure rclone for Google Drive (service account)
      #   if: steps.skipcheck.outputs.already == 'false'
      #   run: |
      #     echo '${{ secrets.GDRIVE_SA_JSON }}' > sa.json
      #     printf "[gdrive]\n" > rclone.conf
      #     printf "type = drive\n" >> rclone.conf
      #     printf "scope = drive\n" >> rclone.conf
      #     printf "service_account_file = %s/sa.json\n" "${{ github.workspace }}" >> rclone.conf
      #
      # - name: Upload today's CSVs to Google Drive
      #   if: steps.skipcheck.outputs.already == 'false'
      #   env:
      #     RCLONE_CONFIG: ${{ github.workspace }}/rclone.conf
      #   run: |
      #     DATE_DIR="${{ steps.stamp.outputs.date_dir }}"
      #     rclone copy "$DATE_DIR" gdrive: --drive-root-folder-id "${{ secrets.GDRIVE_FOLDER_ID }}" -v
