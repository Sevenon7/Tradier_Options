name: LEAPS Daily Overlay

on:
  # 11:00 AM PT ≈ 18:00 UTC (DST) and 19:00 UTC (Standard)
  schedule:
    - cron: '0 18 * * 1-5'
    - cron: '0 19 * * 1-5'
  workflow_dispatch: {}

# Prevent overlapping runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  run-overlay:
    runs-on: ubuntu-latest
    env:
      TRADIER_TOKEN: ${{ secrets.TRADIER_TOKEN }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v5

      # >>> NEW STEP: ensure a dependency file exists BEFORE setup-python (required for cache: pip)
      - name: Ensure requirements.txt for caching
        run: |
          if [ ! -f requirements.txt ]; then
            printf "requests>=2.31,<3\npandas>=2.2,<3\n" > requirements.txt
          fi

      - name: Set up Python
        uses: actions/setup-python@v6.0.0
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Mask token (extra safety)
        run: |
          if [ -n "${TRADIER_TOKEN}" ]; then
            echo "::add-mask::${TRADIER_TOKEN}"
          fi

      # Skip second cron if today's folder already exists
      - name: Skip if already ran today
        id: skipcheck
        shell: bash
        run: |
          DATE_DIR="data/$(date -u +%Y-%m-%d)"
          if [ -d "$DATE_DIR" ]; then
            echo "already=true" >> "$GITHUB_OUTPUT"
            echo "Run already completed for $DATE_DIR — skipping."
          else
            echo "already=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Run overlay script (Tradier)
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          set -eo pipefail
          python leaps_batched_cached.py

      - name: Prepare dated folder & move outputs
        if: steps.skipcheck.outputs.already == 'false'
        id: stamp
        shell: bash
        run: |
          DATE_DIR="data/$(date -u +%Y-%m-%d)"
          mkdir -p "$DATE_DIR"
          [ -f overlay_vwap_macd_rsi.csv ] && mv overlay_vwap_macd_rsi.csv "$DATE_DIR/overlay_vwap_macd_rsi.csv" || touch "$DATE_DIR/overlay_vwap_macd_rsi.csv"
          [ -f option_pl.csv ]               && mv option_pl.csv               "$DATE_DIR/option_pl.csv"               || touch "$DATE_DIR/option_pl.csv"
          [ -f gapdown_above_100sma.csv ]    && mv gapdown_above_100sma.csv    "$DATE_DIR/gapdown_above_100sma.csv"    || touch "$DATE_DIR/gapdown_above_100sma.csv"
          printf "# LEAPS Overlay (%s UTC)\n\nArtifacts:\n- overlay_vwap_macd_rsi.csv\n- option_pl.csv\n- gapdown_above_100sma.csv\n" "$(date -u)" > "$DATE_DIR/SUMMARY.md"
          echo "date_dir=$DATE_DIR" >> "$GITHUB_OUTPUT"

      - name: Compute RAW URLs (for easy copy/paste)
        if: steps.skipcheck.outputs.already == 'false'
        id: raw
        shell: bash
        run: |
          REPO="${{ github.repository }}"
          DATE_DIR="${{ steps.stamp.outputs.date_dir }}"
          echo "raw_overlay=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/overlay_vwap_macd_rsi.csv" >> "$GITHUB_OUTPUT"
          echo "raw_pl=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/option_pl.csv" >> "$GITHUB_OUTPUT"
          echo "raw_gap=https://raw.githubusercontent.com/${REPO}/main/${DATE_DIR}/gapdown_above_100sma.csv" >> "$GITHUB_OUTPUT"

      - name: Build JSON digest for ChatGPT (adds to Summary)
        if: steps.skipcheck.outputs.already == 'false'
        env:
          DATE_DIR: ${{ steps.stamp.outputs.date_dir }}
          RAW_OVERLAY: ${{ steps.raw.outputs.raw_overlay }}
          RAW_PL: ${{ steps.raw.outputs.raw_pl }}
          RAW_GAP: ${{ steps.raw.outputs.raw_gap }}
        run: |
          python - << 'PY'
          import os, json, pandas as pd
          date_dir = os.environ["DATE_DIR"]
          def read_csv(p):
              try: return pd.read_csv(p)
              except Exception: return pd.DataFrame()
          ov = read_csv(f"{date_dir}/overlay_vwap_macd_rsi.csv")
          pl = read_csv(f"{date_dir}/option_pl.csv")
          gp = read_csv(f"{date_dir}/gapdown_above_100sma.csv")
          keep_ov = ["Ticker","RSI14","MACD>Signal","VWAP","LastPx","Px_vs_VWAP","SMA100","Gap%","Guidance"]
          keep_pl = ["Contract","OCC","Bid","Ask","Last","MidUsed","Entry","Contracts","P/L($)","P/L(%)","IV"]
          keep_gp = ["Ticker","Gap%","Close","SMA100"]
          ov = ov[[c for c in keep_ov if c in ov.columns]].copy()
          pl = pl[[c for c in keep_pl if c in pl.columns]].copy()
          gp = gp[[c for c in keep_gp if c in gp.columns]].copy()
          digest = {
            "raw_links": {
              "overlay": os.environ.get("RAW_OVERLAY",""),
              "option_pl": os.environ.get("RAW_PL",""),
              "gap_screen": os.environ.get("RAW_GAP","")
            },
            "overlay": json.loads(ov.to_json(orient="records")),
            "option_pl": json.loads(pl.to_json(orient="records")),
            "gap_screen": json.loads(gp.to_json(orient="records")),
          }
          block = "```json\n" + json.dumps(digest, indent=2) + "\n```"
          print(block)
          with open(os.environ["GITHUB_STEP_SUMMARY"], "a", encoding="utf-8") as f:
              f.write("### JSON Digest for ChatGPT\n\n")
              f.write(block + "\n")
          PY

      - name: Append RAW links to job summary
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          {
            echo "### Raw CSV links (UTC $(date -u))"
            echo "- ${{ steps.raw.outputs.raw_overlay }}"
            echo "- ${{ steps.raw.outputs.raw_pl }}"
            echo "- ${{ steps.raw.outputs.raw_gap }}"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Commit results to repo
        if: steps.skipcheck.outputs.already == 'false'
        run: |
          set -eo pipefail
          git config user.name  "${{ github.actor }}"
          git config user.email "${{ github.actor }}@users.noreply.github.com"
          git add "${{ steps.stamp.outputs.date_dir }}"
          git commit -m "LEAPS overlay auto-run: ${{ steps.stamp.outputs.date_dir }}"
          git push

      - name: Upload artifacts
        if: steps.skipcheck.outputs.already == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: leaps-report
          path: |
            ${{ steps.stamp.outputs.date_dir }}/overlay_vwap_macd_rsi.csv
            ${{ steps.stamp.outputs.date_dir }}/option_pl.csv
            ${{ steps.stamp.outputs.date_dir }}/gapdown_above_100sma.csv
            ${{ steps.stamp.outputs.date_dir }}/SUMMARY.md
          if-no-files-found: warn
          

      # --- OPTIONAL: Mirror to Google Drive (uncomment and add secrets to use) ---
      # - name: Install rclone
      #   if: steps.skipcheck.outputs.already == 'false'
      #   run: |
      #     sudo apt-get update -y
      #     sudo apt-get install -y unzip
      #     curl -L https://downloads.rclone.org/rclone-current-linux-amd64.zip -o rclone.zip
      #     unzip -q rclone.zip
      #     sudo cp rclone-*-linux-amd64/rclone /usr/local/bin/rclone
      #
      # - name: Configure rclone for Google Drive (service account)
      #   if: steps.skipcheck.outputs.already == 'false'
      #   run: |
      #     echo '${{ secrets.GDRIVE_SA_JSON }}' > sa.json
      #     printf "[gdrive]\n" > rclone.conf
      #     printf "type = drive\n" >> rclone.conf
      #     printf "scope = drive\n" >> rclone.conf
      #     printf "service_account_file = %s/sa.json\n" "${{ github.workspace }}" >> rclone.conf
      #
      # - name: Upload today's CSVs to Google Drive
      #   if: steps.skipcheck.outputs.already == 'false'
      #   env:
      #     RCLONE_CONFIG: ${{ github.workspace }}/rclone.conf
      #   run: |
      #     DATE_DIR="${{ steps.stamp.outputs.date_dir }}"
      #     rclone copy "$DATE_DIR" gdrive: --drive-root-folder-id "${{ secrets.GDRIVE_FOLDER_ID }}" -v
